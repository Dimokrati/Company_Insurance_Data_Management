import pandas as pd
import logging
from datetime import datetime
from sqlalchemy import create_engine, text
from util.config_handler import ConfigHandler

LOGGER = logging.getLogger(__name__)

class DbHandler:
    def __init__(self, db_name):
        self.config_handler = ConfigHandler()
        self.db_name = db_name
        self.params = self.config_handler.get_db_params(db_name)
        self.db_user = self.params['db_user']
        self.db_password = self.params['db_password']
        self.db_host = self.params['db_host']
        self.db_port = self.params['db_port']
        self.db_name = self.params['db_name']
        self.connection_str = f'postgresql://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{self.db_name}'
        self.engine = create_engine(self.connection_str)

    def split_dataframe_by_prefix(self, df, prefixes):
        """
        Splits a DataFrame into smaller DataFrames based on column prefixes.

        This function iterates through a list of prefixes and creates a dictionary to store resulting DataFrames.
        For each prefix, it identifies columns that start with that prefix followed by an underscore '_'.
        A new DataFrame containing only those columns is created and added to the dictionary with the prefix as the key.
        The column names in the new DataFrame are modified to remove the original prefix and underscore.

        Args:
            df (pandas.DataFrame): The DataFrame to split.
            prefixes (list): A list of prefixes to use for splitting the DataFrame.

        Returns:
            dict: A dictionary where keys are prefixes and values are the corresponding DataFrames containing columns with those prefixes.
        """
        split_dfs = {}
        for prefix in prefixes:
            columns = [col for col in df.columns if col.startswith(prefix + '_')]
            split_dfs[prefix] = df[columns].copy()
            split_dfs[prefix].columns = [col[len(prefix)+1:] for col in columns]  # Remove prefix from column names
        return split_dfs
    

    def create_date_data(self):
        """
        Generates a DataFrame containing various date-related data points for today's date.

        This function extracts components from today's date and creates a DataFrame with these values.
        The DataFrame includes columns for day, month, year, day of week, day of month, day of year, week of year, and quarter.

        Returns:
            pandas.DataFrame: A DataFrame containing the generated date data.
        """
        today = datetime.now().date()
        
        day = today.day
        month = today.month
        year = today.year
        day_of_week = today.weekday()  # Monday is 0 and Sunday is 6
        day_of_month = today.day
        day_of_year = today.timetuple().tm_yday
        week_of_year = today.isocalendar()[1]
        quarter = (today.month - 1) // 3 + 1

        # Create a list of dictionaries with the same values for all 7 rows
        data = [{
            'dates_date': today,
            'dates_day': day,
            'dates_month': month,
            'dates_year': year,
            'dates_day_of_weak': day_of_week,
            'dates_day_of_month': day_of_month,
            'dates_day_of_year': day_of_year,
            'dates_week_of_year': week_of_year,
            'dates_quarter': quarter
        } for _ in range(7)]
        
        df = pd.DataFrame(data)
        return df
    
    
    def insert_data(self, df, table_name, schema_name):
        """
        Inserts data from the DataFrame into a table, combining with date information.

        This function combines the provided DataFrame (`df`) with the date information generated by the `create_date_data` function.
        The combined DataFrame is then inserted into the specified table (`table_name`) within the given schema (`schema_name`).
        The `if_exists='append'` parameter ensures data is appended to the existing table without overwriting it.
        The function also logs a message indicating successful data insertion.

        Args:
            df (pandas.DataFrame): The DataFrame containing the data to insert.
            table_name (str): The name of the table to insert data into.
            schema_name (str): The name of the schema where the table resides.
        """
        # split_dfs = self.split_dataframe_by_prefix(df, prefixes.keys())
        date_data = self.create_date_data()
        # date_data.to_sql("raw_dates", self.engine, schema = schema_name, if_exists='append', index=False)
        # LOGGER.info("Inserted data into table raw_dates")
        # for prefix, table_name in prefixes.items():
            # split_dfs[prefix].to_sql(table_name, self.engine, schema = schema_name, if_exists='append', index=False)
        res_df = pd.concat([df,date_data], axis=1)
        res_df.to_sql(table_name, self.engine, schema=schema_name, if_exists='append', index=False)
        LOGGER.info(f"Inserted data into table raw_data")
        


    def extract_data(self,engine):
        """
        Extracts raw data from the database using a configured query.

        This function retrieves data from the database based on a query stored in the configuration handler.

        Args:
            engine (sqlalchemy.engine.Engine): A SQLAlchemy engine object for connecting to the database.

        Returns:
            pandas.DataFrame: A pandas DataFrame containing the extracted raw data.
        """
        query = self.config_handler.get_raw_data_query("query_raw_data")
        df = pd.read_sql(query, engine)
        return df
    
    def remove_duplicates(self,df, subset_columns, keep='last'):
        """
        Removes duplicate rows based on a subset of columns, keeping the most recent record.

        Args:
            df (pandas.DataFrame): The DataFrame containing the data.
            subset_columns (list): A list of column names to use for identifying duplicates.
            keep (str, optional): How to handle duplicates. Defaults to 'last' (keep most recent).
                                    Other options include 'first' (keep oldest) or False (remove all).

        Returns:
            pandas.DataFrame: A new DataFrame with duplicates removed.
        """
        return df.drop_duplicates(subset=subset_columns, keep=keep)
    

    def insert_unique_data(self, prefixes, schema_name = "curated"):
        """
        Extracts data, removes duplicates, splits by prefix, and inserts into curated tables.

        This function performs the following steps:
            1. Extracts raw data from the database using the `extract_data` function.
            2. Removes duplicate rows from the extracted data using the `remove_duplicates` function.
            3. Splits the deduplicated data into smaller DataFrames based on column prefixes using `split_dataframe_by_prefix`.
            4. Iterates through the prefixes and corresponding table names:
                - Inserts each split DataFrame into its designated table within the specified schema (`schema_name`).
                - Uses `if_exists='append'` to append data without overwriting existing content.
                - Logs a message for each successful insertion.
            5. Logs a final message indicating all data has been saved successfully.

        Args:
            prefixes (dict): A dictionary where keys are prefixes and values are corresponding table names.
            schema_name (str, optional): The schema name where the curated tables reside. Defaults to "curated".
        """
        raw_data = self.extract_data(self.engine)
        unique_data = self.remove_duplicates(raw_data, ['vehicles_registration_number', 'policyholders_cin_rc', 'policyholders_phone_number', 'policyholders_license_number'])
        split_dfs = self.split_dataframe_by_prefix(unique_data, prefixes.keys())

        # date_data.to_sql("raw_dates", self.engine, schema = schema_name, if_exists='append', index=False)
        # LOGGER.info("Inserted data into table raw_dates")
        for prefix, table_name in prefixes.items():
            split_dfs[prefix].to_sql(table_name, self.engine, schema = schema_name, if_exists='append', index=False)
            LOGGER.info(f"Inserted data in table {table_name}")
        LOGGER.info(f"All data saved succesfully")

        
